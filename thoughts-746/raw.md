
<a href="https://www.docker.com/blog/build-ai-agents-with-docker-compose/">
    <img
        src="https://shots.wayl.one/shot/?url=https://www.docker.com/blog/build-ai-agents-with-docker-compose/&height=450&width=800&scaled_width=800&scaled_height=450&selectors=""
        alt="shot of post - ðŸ’­ Docker Brings Compose to the AI Agent Era | Docker"
        height=450
        width=800
    >
</a>

Here's my thought on <a href="https://www.docker.com/blog/build-ai-agents-with-docker-compose/">ðŸ’­ Docker Brings Compose to the AI Agent Era | Docker</a>

---

Seems like docker is leaning harder into compose - which is great for me as a heavy compose user. I had heard about some of the LLM enablements directly through docker desktop - for example taking fuller advantage of the host's compute power without paying the penalty of the nvidia runtime or something... I can't claim to have followed it all but I heard "run LLMs in docker directly for a bigger boost" and I'm in.

---

!!! note
     This is one of [[ my-thoughts ]]. I picked this up from [Waylon Walker](https://waylonwalker.com)(https://thoughts.waylonwalker.com). It's a short note that I make about someone else's
     content online.  Learn more about the process [[ thoughts ]]


---

['docker', 'ai', 'homelab', 'thoughts']
        