<section class="post-terminal   ">
    <figure class="post-terminal__media">
        <div class="post-terminal__media-frame">
            <img src="https://cdn.statically.io/gh/pypeaday/images.pype.dev/main/blog-media/20251006105246_8accdc76.png" alt="Speakr For Recording and Transcribing at Home cover image">
        </div>
    </figure>

    <article class="post-terminal__article">
<section class="post-header mb-8">
    <h1 id="title" style="font-size: 4rem; line-height: 1.1; font-weight: 800;" class="text-6xl md:text-7xl font-extrabold gradient-text mb-4 post-title-large">Speakr For Recording and Transcribing at Home</h1>
    <div class="flex items-center text-sm text-text-main/80 mb-6">
        <time datetime="2025-11-11">
            November 11, 2025
        </time>
    </div>
    <div class="flex flex-wrap gap-2">
            <a href="https://pype.dev//tags/speakr/" class="inline-block bg-primary-light text-accent-cool text-xs font-medium px-3 py-1 rounded-full hover:bg-primary-light/80 transition-colors border border-accent-cool/20 hover-lift">
                #speakr
            </a>
            <a href="https://pype.dev//tags/tech/" class="inline-block bg-primary-light text-accent-cool text-xs font-medium px-3 py-1 rounded-full hover:bg-primary-light/80 transition-colors border border-accent-cool/20 hover-lift">
                #tech
            </a>
    </div>
</section>        <section class="post-terminal__body prose dark:prose-invert">
            <p>I have been using Whisper-WebUI for several months in my homelab to record and
transcribe myself thinking out loud. It's been great. Then I came across
<a href="https://github.com/murtaza-nasir/speakr">speakr</a> which is like that but more
feature rich in what I wanted out of the WebUI. Specifically I get a nicer UI
with transcriptions, a chat window, built-in summarization, and diarization
support (WebUI has this too but it's a little nicer in Speakr in my opinion).</p>
<h2 id="pic">Pic <a class="header-anchor" href="#pic"><svg class="heading-permalink" aria-hidden="true" fill="currentColor" focusable="false" height="1em" viewBox="0 0 24 24" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></a></h2>
<p><img src="https://cdn.statically.io/gh/pypeaday/images.pype.dev/main/blog-media/20250824120404_da722d66.png" alt="20250824120404_da722d66.png" /></p>
<p>The UI is a little busy but handy for what I'm after in the mornings or when
I'm trying to mind-dump somewhere I can conveniently explore later.</p>
<h2 id="speaker-identification">Speaker Identification <a class="header-anchor" href="#speaker-identification"><svg class="heading-permalink" aria-hidden="true" fill="currentColor" focusable="false" height="1em" viewBox="0 0 24 24" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></a></h2>
<p>Requires HuggingFace Token to pull the models that perform <a href="https://en.wikipedia.org/wiki/Speaker_diarisation">Speaker
diarisation</a> - ie.
identifying different speakers</p>
<p>Here's an example from an episode of Hybrid Cloud Show.</p>
<p><img src="https://cdn.statically.io/gh/pypeaday/images.pype.dev/main/blog-media/20250826124040_48c8d2ce.png" alt="20250826124040_48c8d2ce.png" /></p>

        </section>
    </article>
</section>